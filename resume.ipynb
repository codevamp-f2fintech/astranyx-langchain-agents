{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "860c4db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è Cloud Collection already exists\n",
      "status=<CollectionStatus.GREEN: 'green'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> warnings=None indexed_vectors_count=0 points_count=243 segments_count=2 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=384, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=None), shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors=None), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None, inline_storage=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=10000, flush_interval_sec=5, max_optimization_threads=None), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0, wal_retain_closed=1), quantization_config=None, strict_mode_config=StrictModeConfigOutput(enabled=True, max_query_limit=None, max_timeout=None, unindexed_filtering_retrieve=False, unindexed_filtering_update=False, search_max_hnsw_ef=None, search_allow_exact=None, search_max_oversampling=None, upsert_max_batchsize=None, max_collection_vector_size_bytes=None, read_rate_limit=None, write_rate_limit=None, max_collection_payload_size_bytes=None, max_points_count=None, filter_max_conditions=None, condition_max_size=None, multivector_config=None, sparse_config=None, max_payload_index_count=100), metadata=None) payload_schema={}\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "cloud_client = QdrantClient(\n",
    "    url=os.getenv(\"QDRANT_URL\"),\n",
    "    api_key=os.getenv(\"QDRANT_API_KEY\")\n",
    ")\n",
    "\n",
    "if not cloud_client.collection_exists(\"resumes\"):\n",
    "    cloud_client.create_collection(\n",
    "        collection_name=\"resumes\",\n",
    "        vectors_config=VectorParams(\n",
    "            size=384,   # SAME AS LOCAL\n",
    "            distance=Distance.COSINE\n",
    "        )\n",
    "    )\n",
    "    print(\"‚úÖ Cloud Collection created\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Cloud Collection already exists\")\n",
    "info = cloud_client.get_collection(\"resumes\")\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d1e37c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8a0a330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting migration...\n",
      "Transferred: 50\n",
      "Transferred: 100\n",
      "Transferred: 150\n",
      "Transferred: 200\n",
      "Transferred: 243\n",
      "‚úÖ Migration Complete\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import PointStruct\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os \n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "# Local Docker\n",
    "local_client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "# Cloud\n",
    "cloud_client = QdrantClient(\n",
    "    url=os.getenv(\"QDRANT_URL\"),\n",
    "    api_key=os.getenv(\"QDRANT_API_KEY\"),\n",
    "    timeout=120\n",
    ")\n",
    "\n",
    "collection_name = \"resumes\"\n",
    "batch_size = 50\n",
    "offset = None\n",
    "total = 0\n",
    "\n",
    "print(\"üöÄ Starting migration...\")\n",
    "\n",
    "while True:\n",
    "    records, offset = local_client.scroll(\n",
    "        collection_name=collection_name,\n",
    "        limit=batch_size,\n",
    "        offset=offset,\n",
    "        with_vectors=True,\n",
    "        with_payload=True\n",
    "    )\n",
    "\n",
    "    if not records:\n",
    "        break\n",
    "\n",
    "    points = [\n",
    "        PointStruct(\n",
    "            id=record.id,\n",
    "            vector=record.vector,\n",
    "            payload=record.payload\n",
    "        )\n",
    "        for record in records\n",
    "    ]\n",
    "\n",
    "    cloud_client.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=points\n",
    "    )\n",
    "\n",
    "    total += len(points)\n",
    "    print(f\"Transferred: {total}\")\n",
    "\n",
    "    if offset is None:\n",
    "        break\n",
    "\n",
    "print(\"‚úÖ Migration Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7cb6a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ AGENT STARTED: RESUME INDEXING\n",
      "üìä MongoDB + AWS S3 + Qdrant\n",
      "‚úÖ AWS verified\n",
      "‚úÖ MongoDB connected\n",
      "‚ÑπÔ∏è Qdrant collection exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103/103 [00:00<00:00, 335.24it/s, Materializing param=pooler.dense.weight]                             \n",
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embedding model loaded\n",
      "üìå Pending/open resumes count: 15\n",
      "\n",
      "üìÑ Processing 684d489a7d783615f6da851e | Job: 684d43cb7d783615f6da82c7\n",
      "   üì• Downloading: uploads/1749895321436-Khushi singh resume  (1).pdf\n",
      "‚ùå Failed ‚Üí Unable to get page count. Is poppler installed and in PATH?\n",
      "\n",
      "üìÑ Processing 684d4d617d783615f6da8706 | Job: 684d43cb7d783615f6da82c7\n",
      "   üì• Downloading: uploads/1749896543506-WhatsApp Image 2025-06-14 at 3.45.00 PM.pdf\n",
      "‚ùå Failed ‚Üí Unable to get page count. Is poppler installed and in PATH?\n",
      "\n",
      "üìÑ Processing 684d57808c77325205caf83b | Job: 684d448a7d783615f6da8313\n",
      "   üì• Downloading: uploads/1749899135124-WhatsApp Image 2025-06-14 at 4.26.09 PM.pdf\n",
      "‚ùå Failed ‚Üí Unable to get page count. Is poppler installed and in PATH?\n",
      "\n",
      "üìÑ Processing 6852adcdbcf10b931eb7c420 | Job: 6852ad6bbcf10b931eb7c3af\n",
      "   üì• Downloading: uploads/1750248908595-infosis.jfif\n",
      "‚ùå Failed ‚Üí Unable to get page count. Is poppler installed and in PATH?\n",
      "\n",
      "üìÑ Processing 6868b4048a09e3fb00a486db | Job: 6868b03a8a09e3fb00a486b2\n",
      "   üì• Downloading: uploads/1751692290628-Banking resume (1).pdf\n",
      "‚ùå Failed ‚Üí Unable to get page count. Is poppler installed and in PATH?\n",
      "\n",
      "üìÑ Processing 6889c1ceef990c0c1cb1f744 | Job: 684d43cb7d783615f6da82c7\n",
      "   üì• Downloading: uploads/1753858508411-PDFGallery_20250323_124718 (1).pdf\n",
      "‚ùå Failed ‚Üí Unable to get page count. Is poppler installed and in PATH?\n",
      "\n",
      "üìÑ Processing 688b0ff1da9aa50734d9458d | Job: 688b0f7bda9aa50734d9455c\n",
      "   üì• Downloading: uploads/1753944048258-Prince Resume 2025 (1).pdf\n",
      "‚ùå Failed ‚Üí Unable to get page count. Is poppler installed and in PATH?\n",
      "\n",
      "üìÑ Processing 6895ae69bb76c83d0d981d7c | Job: 684d43cb7d783615f6da82c7\n",
      "   üì• Downloading: uploads/1754639975686-monudcl40gmailcom (1).pdf\n",
      "‚ùå Failed ‚Üí Unable to get page count. Is poppler installed and in PATH?\n",
      "\n",
      "üìÑ Processing 689c277077de8619092ef7b1 | Job: 684d43cb7d783615f6da82c7\n",
      "   üì• Downloading: uploads/1755064175674-Haya Rizvi.pdf\n",
      "‚ùå Failed ‚Üí Unable to get page count. Is poppler installed and in PATH?\n",
      "\n",
      "üìÑ Processing 68b6cf02d85d1d02ba91b452 | Job: 688b0f7bda9aa50734d9455c\n",
      "   üì• Downloading: uploads/1756811008265-WhatsApp Image 2025-09-02 at 4.24.47 PM.pdf\n",
      "‚ùå Failed ‚Üí Unable to get page count. Is poppler installed and in PATH?\n",
      "üìå Pending/open resumes count: 5\n",
      "\n",
      "üìÑ Processing 68bfc7e872d20e94cb809df5 | Job: 684d43cb7d783615f6da82c7\n",
      "   üì• Downloading: uploads/1757399014476-DocScanner 09-Sep-2025 11-44 AM.pdf\n",
      "‚ùå Failed ‚Üí Unable to get page count. Is poppler installed and in PATH?\n",
      "\n",
      "üìÑ Processing 68e8e29358d5eb3f968312d2 | Job: 68e8be3d9cf549d5a05b71e4\n",
      "   üì• Downloading: https://www.antennahouse.com/hubfs/xsl-fo-sample/pdf/basic-link-1.pdf\n",
      "‚ùå Failed ‚Üí An error occurred (NoSuchKey) when calling the GetObject operation: The specified key does not exist.\n",
      "\n",
      "üìÑ Processing 68e8e29358d5eb3f968312d6 | Job: 68e8bd849cf549d5a05b71d7\n",
      "   üì• Downloading: https://www.antennahouse.com/hubfs/xsl-fo-sample/pdf/basic-link-1.pdf\n",
      "‚ùå Failed ‚Üí An error occurred (NoSuchKey) when calling the GetObject operation: The specified key does not exist.\n",
      "\n",
      "üìÑ Processing 6943b71fd7e30a673d9b8dcd | Job: 690c4d35d9bdec6011e9feb7\n",
      "   üì• Downloading: uploads/1766045469914-Green leaf traders.pdf\n",
      "‚ùå Failed ‚Üí Unable to get page count. Is poppler installed and in PATH?\n",
      "\n",
      "üìÑ Processing 694a59e7c61f3816a822d8b7 | Job: 694a4eb00259460b701ec177\n",
      "   üì• Downloading: uploads/1766480358041-Green leaf traders.pdf\n",
      "‚ùå Failed ‚Üí Unable to get page count. Is poppler installed and in PATH?\n",
      "üìå Pending/open resumes count: 0\n",
      "‚úÖ No open resumes pending\n",
      "\n",
      "üéØ Agent finished successfully\n",
      "‚úÖ MongoDB closed\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import boto3\n",
    "import fitz  # PyMuPDF\n",
    "from dotenv import load_dotenv\n",
    "from pymongo import MongoClient\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import PointStruct, VectorParams, Distance\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_bytes\n",
    "import pytesseract\n",
    "\n",
    "# ================= TESSERACT CONFIG =================\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe\"\n",
    "os.environ[\"TESSDATA_PREFIX\"] = r\"C:\\Program Files (x86)\\Tesseract-OCR\"\n",
    "\n",
    "# ================= LOAD ENV =================\n",
    "load_dotenv()\n",
    "\n",
    "AWS_ACCESS_KEY = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "AWS_REGION = os.getenv(\"AWS_REGION\")\n",
    "S3_BUCKET = os.getenv(\"AWS_S3_BUCKET\")\n",
    "\n",
    "MONGO_URI = os.getenv(\"MONGODB_URI\")\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\")\n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")  # <--- new\n",
    "\n",
    "# ================= CHECK ENV =================\n",
    "for var_name, var in [\n",
    "    (\"AWS_ACCESS_KEY\", AWS_ACCESS_KEY),\n",
    "    (\"AWS_SECRET_KEY\", AWS_SECRET_KEY),\n",
    "    (\"AWS_REGION\", AWS_REGION),\n",
    "    (\"S3_BUCKET\", S3_BUCKET),\n",
    "    (\"MONGO_URI\", MONGO_URI),\n",
    "    (\"QDRANT_URL\", QDRANT_URL),\n",
    "    (\"QDRANT_API_KEY\", QDRANT_API_KEY)\n",
    "]:\n",
    "    if not var:\n",
    "        raise RuntimeError(f\"‚ùå Environment variable {var_name} missing\")\n",
    "\n",
    "DB_NAME = \"ats\"\n",
    "COLLECTION_NAME = \"applications\"\n",
    "QDRANT_COLLECTION = \"resumes\"\n",
    "BATCH_SIZE = 10\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "# ================= START =================\n",
    "print(\"\\nü§ñ AGENT STARTED: RESUME INDEXING\")\n",
    "print(\"üìä MongoDB + AWS S3 + Qdrant\")\n",
    "\n",
    "# ================= AWS =================\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id=AWS_ACCESS_KEY,\n",
    "    aws_secret_access_key=AWS_SECRET_KEY,\n",
    "    region_name=AWS_REGION\n",
    ")\n",
    "s3.list_buckets()\n",
    "print(\"‚úÖ AWS verified\")\n",
    "\n",
    "# ================= MongoDB =================\n",
    "mongo = MongoClient(MONGO_URI)\n",
    "db = mongo[DB_NAME]\n",
    "applications = db[COLLECTION_NAME]\n",
    "print(\"‚úÖ MongoDB connected\")\n",
    "\n",
    "# ================= QDRANT =================\n",
    "qdrant = QdrantClient(\n",
    "    url=QDRANT_URL,\n",
    "    api_key=QDRANT_API_KEY,\n",
    "    prefer_grpc=False,  # REST API (required for Cloud)\n",
    "    timeout=120\n",
    ")\n",
    "\n",
    "# Ensure collection exists\n",
    "if not qdrant.collection_exists(QDRANT_COLLECTION):\n",
    "    qdrant.create_collection(\n",
    "        collection_name=QDRANT_COLLECTION,\n",
    "        vectors_config=VectorParams(\n",
    "            size=384,\n",
    "            distance=Distance.COSINE\n",
    "        )\n",
    "    )\n",
    "    print(\"‚úÖ Qdrant collection created\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Qdrant collection exists\")\n",
    "\n",
    "# ================= MODEL =================\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "print(\"‚úÖ Embedding model loaded\")\n",
    "\n",
    "# ================= HELPERS =================\n",
    "def mongo_id_to_uuid(mongo_id: str) -> str:\n",
    "    return str(uuid.uuid5(uuid.NAMESPACE_DNS, mongo_id))\n",
    "\n",
    "def extract_s3_key(url: str) -> str:\n",
    "    return url.split(\".amazonaws.com/\")[-1]\n",
    "\n",
    "def extract_text_from_s3(url: str) -> str:\n",
    "    key = extract_s3_key(url)\n",
    "    print(f\"   üì• Downloading: {key}\")\n",
    "\n",
    "    obj = s3.get_object(Bucket=S3_BUCKET, Key=key)\n",
    "    file_bytes = obj[\"Body\"].read()\n",
    "    text = \"\"\n",
    "\n",
    "    # ---------- IMAGE ----------\n",
    "    if key.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "        image = Image.open(io.BytesIO(file_bytes))\n",
    "        text = pytesseract.image_to_string(image)\n",
    "\n",
    "    # ---------- PDF ----------\n",
    "    else:\n",
    "        with fitz.open(stream=file_bytes, filetype=\"pdf\") as doc:\n",
    "            for page in doc:\n",
    "                text += page.get_text()\n",
    "        # OCR fallback if PDF has no extractable text\n",
    "        if not text.strip():\n",
    "            images = convert_from_bytes(file_bytes)\n",
    "            for img in images:\n",
    "                text += pytesseract.image_to_string(img)\n",
    "\n",
    "    if not text.strip():\n",
    "        raise ValueError(\"No text extracted\")\n",
    "\n",
    "    print(f\"   üìÑ Extracted {len(text)} chars\")\n",
    "    return text\n",
    "\n",
    "\n",
    "# ================= AGENT =================\n",
    "def resume_indexing_agent():\n",
    "    \"\"\"\n",
    "    Only index resumes whose resume_status is 'open'.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        # ----------------- QUERY -----------------\n",
    "        query = {\n",
    "            \"resume\": {\"$exists\": True, \"$regex\": \"^http\"},\n",
    "            \"resume_status\": \"open\",  # ONLY open resumes\n",
    "            \"$or\": [\n",
    "                {\"rag_uploaded\": False},\n",
    "                {\"rag_uploaded\": \"False\"},  # in case it is stored as string\n",
    "                {\"rag_uploaded\": {\"$exists\": False}}\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        pending_count = applications.count_documents(query)\n",
    "        print(f\"üìå Pending/open resumes count: {pending_count}\")\n",
    "\n",
    "        batch = list(applications.find(query).limit(BATCH_SIZE))\n",
    "        if not batch:\n",
    "            print(\"‚úÖ No open resumes pending\")\n",
    "            break\n",
    "\n",
    "        points = []\n",
    "\n",
    "        for app in batch:\n",
    "            app_id = str(app[\"_id\"])\n",
    "            job_id = str(app.get(\"jobID\", \"\"))\n",
    "            print(f\"\\nüìÑ Processing {app_id} | Job: {job_id}\")\n",
    "\n",
    "            try:\n",
    "                text = extract_text_from_s3(app[\"resume\"])\n",
    "                embedding = model.encode(text).tolist()\n",
    "\n",
    "                points.append(\n",
    "                    PointStruct(\n",
    "                        id=mongo_id_to_uuid(app_id),\n",
    "                        vector=embedding,\n",
    "                        payload={\n",
    "                            \"application_id\": app_id,\n",
    "                            \"job_id\": job_id,\n",
    "                            \"resume_text\": text[:1500]\n",
    "                        }\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                # Update only open resumes\n",
    "                applications.update_one(\n",
    "                    {\"_id\": app[\"_id\"]},\n",
    "                    {\"$set\": {\n",
    "                        \"resume_status\": \"indexed\",\n",
    "                        \"rag_uploaded\": True,\n",
    "                        \"indexed_at\": time.time()\n",
    "                    }}\n",
    "                )\n",
    "                print(\"‚úÖ Indexed\")\n",
    "\n",
    "            except Exception as e:\n",
    "                applications.update_one(\n",
    "                    {\"_id\": app[\"_id\"]},\n",
    "                    {\"$set\": {\n",
    "                        \"resume_status\": \"failed\",\n",
    "                        \"error\": str(e)\n",
    "                    }}\n",
    "                )\n",
    "                print(f\"‚ùå Failed ‚Üí {e}\")\n",
    "\n",
    "        if points:\n",
    "            qdrant.upsert(\n",
    "                collection_name=QDRANT_COLLECTION,\n",
    "                points=points\n",
    "            )\n",
    "            print(f\"üöÄ {len(points)} vectors pushed to Qdrant\")\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "# ================= RUN =================\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        resume_indexing_agent()  # ‚úÖ no arguments needed\n",
    "        print(\"\\nüéØ Agent finished successfully\")\n",
    "    finally:\n",
    "        mongo.close()\n",
    "        print(\"‚úÖ MongoDB closed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "246e9ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ JD MATCHING AGENT STARTED (Best Score Relative Mode)\n",
      "‚úÖ MongoDB connected\n",
      "‚úÖ Qdrant connected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103/103 [00:00<00:00, 153.95it/s, Materializing param=pooler.dense.weight]                             \n",
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embedding model loaded\n",
      "üè¢ Found 3 AI enabled companies\n",
      "\n",
      "üè¢ Running JD Matching For Company: f2fintech\n",
      "üîé Processing company: 682858bb96c2ed0759146648\n",
      "\n",
      "üîé Processing Job: 684920beae8bd1780f520b09\n",
      "üìä Found 0 resumes for this job\n",
      "\n",
      "üîé Processing Job: 684d43cb7d783615f6da82c7\n",
      "üìä Found 161 resumes for this job\n",
      "üèÜ Best Score: 0.5407\n",
      "üéØ Selection Cutoff (63% of Best): 0.3406\n",
      "   ‚ûú 684d489c7d783615f6da8521 | 0.5407 ‚Üí selected\n",
      "   ‚ûú 68e76cac72a5ec1432f67f96 | 0.4242 ‚Üí selected\n",
      "   ‚ûú 68662f868e27a08a98339a69 | 0.4138 ‚Üí selected\n",
      "   ‚ûú 6958d29212dc988d45a83653 | 0.4052 ‚Üí selected\n",
      "   ‚ûú 690c3c73450fd808275d0ef3 | 0.3896 ‚Üí selected\n",
      "   ‚ûú 68a990b40f7a9b9b9c5c9059 | 0.3778 ‚Üí selected\n",
      "   ‚ûú 69391342483e6754327e9e82 | 0.3711 ‚Üí selected\n",
      "   ‚ûú 68d3be5380642c2dbf4d5b64 | 0.3679 ‚Üí selected\n",
      "   ‚ûú 68b68135dbdbc7d4e8742ed6 | 0.3607 ‚Üí selected\n",
      "   ‚ûú 69391281483e6754327e9e4b | 0.3597 ‚Üí selected\n",
      "   ‚ûú 693914c7483e6754327e9ee9 | 0.3512 ‚Üí selected\n",
      "   ‚ûú 68b9273a97d1801b76070552 | 0.3490 ‚Üí selected\n",
      "   ‚ûú 68904ab933d56038c0547863 | 0.3478 ‚Üí selected\n",
      "   ‚ûú 68a2c5d79d52520c6d8d6249 | 0.3218 ‚Üí rejected\n",
      "   ‚ûú 688486e1d376dbaf89969d5d | 0.3090 ‚Üí rejected\n",
      "   ‚ûú 6958d82ef50e074e56f54647 | 0.3088 ‚Üí rejected\n",
      "   ‚ûú 68b688450990b0064f87699d | 0.3037 ‚Üí rejected\n",
      "   ‚ûú 69393dce09d5458fbdf177b8 | 0.3023 ‚Üí rejected\n",
      "   ‚ûú 685cd3327d8281d065581bc9 | 0.2996 ‚Üí rejected\n",
      "   ‚ûú 689d87b13bfdf7e0797a1e7f | 0.2953 ‚Üí rejected\n",
      "   ‚ûú 68871aa70b2912e68f25379f | 0.2949 ‚Üí rejected\n",
      "   ‚ûú 684d4a467d783615f6da858f | 0.2851 ‚Üí rejected\n",
      "   ‚ûú 68a991d00f7a9b9b9c5c9092 | 0.2845 ‚Üí rejected\n",
      "   ‚ûú 68a2f654d427f08bb87f8ba3 | 0.2804 ‚Üí rejected\n",
      "   ‚ûú 689c235d77de8619092ef6b9 | 0.2803 ‚Üí rejected\n",
      "   ‚ûú 6895b45a447e15c6f7154720 | 0.2765 ‚Üí rejected\n",
      "   ‚ûú 687b2b25c1bc4c80f2fe6e59 | 0.2596 ‚Üí rejected\n",
      "   ‚ûú 688761cc5c1c86a3a3cbf712 | 0.2567 ‚Üí rejected\n",
      "   ‚ûú 68836f7d23b3f4fdbd2ea85f | 0.2498 ‚Üí rejected\n",
      "   ‚ûú 685be6166d23c23262115c90 | 0.2373 ‚Üí rejected\n",
      "   ‚ûú 6883702e23b3f4fdbd2ea8a5 | 0.2355 ‚Üí rejected\n",
      "   ‚ûú 685904d390973ae87e65f6f2 | 0.2277 ‚Üí rejected\n",
      "   ‚ûú 684fe30d5f1b61e822457b58 | 0.2267 ‚Üí rejected\n",
      "   ‚ûú 6862779edefc6ec25cb66234 | 0.2266 ‚Üí rejected\n",
      "   ‚ûú 68dcb533be4f0a70c9781db6 | 0.2251 ‚Üí rejected\n",
      "   ‚ûú 685bac33de9f5654720344bf | 0.2208 ‚Üí rejected\n",
      "   ‚ûú 6883725423b3f4fdbd2ea9cb | 0.2197 ‚Üí rejected\n",
      "   ‚ûú 688371bf23b3f4fdbd2ea952 | 0.2161 ‚Üí rejected\n",
      "   ‚ûú 68a44eafd0434b6f724c4b85 | 0.2156 ‚Üí rejected\n",
      "   ‚ûú 684d45737d783615f6da8352 | 0.2149 ‚Üí rejected\n",
      "   ‚ûú 68b7db3482022c55f128d8dc | 0.2134 ‚Üí rejected\n",
      "   ‚ûú 68a57c62a782e632c78e1873 | 0.2109 ‚Üí rejected\n",
      "   ‚ûú 685a45dd370d2614e735c415 | 0.2095 ‚Üí rejected\n",
      "   ‚ûú 68df6610cfa9d7bbe751fb98 | 0.2068 ‚Üí rejected\n",
      "   ‚ûú 68a2e12d9d52520c6d8d65c1 | 0.2064 ‚Üí rejected\n",
      "   ‚ûú 686620148e27a08a98339759 | 0.2060 ‚Üí rejected\n",
      "   ‚ûú 68b8185a9e1521b7a81473d7 | 0.2052 ‚Üí rejected\n",
      "   ‚ûú 68d6484b7bc316c0b2d6c952 | 0.2043 ‚Üí rejected\n",
      "   ‚ûú 68a42ad09e5493e450cb49e4 | 0.2033 ‚Üí rejected\n",
      "   ‚ûú 685fa2e4fa0002c563647d85 | 0.2030 ‚Üí rejected\n",
      "   ‚ûú 688b1e2233b452d405e5f3ef | 0.2018 ‚Üí rejected\n",
      "   ‚ûú 6890469733d56038c05477f1 | 0.2018 ‚Üí rejected\n",
      "   ‚ûú 687773603808aff814a43287 | 0.2012 ‚Üí rejected\n",
      "   ‚ûú 6939140e483e6754327e9eb9 | 0.2007 ‚Üí rejected\n",
      "   ‚ûú 68a6ae2820642e69e649a3ae | 0.1988 ‚Üí rejected\n",
      "   ‚ûú 68997d48310d8d7ef36e811d | 0.1961 ‚Üí rejected\n",
      "   ‚ûú 69142fc370c72f8843d346b5 | 0.1960 ‚Üí rejected\n",
      "   ‚ûú 685509fe1699190af3ef9616 | 0.1944 ‚Üí rejected\n",
      "   ‚ûú 68b92f09a97c1a39de589b12 | 0.1941 ‚Üí rejected\n",
      "   ‚ûú 689acbf1b4c6c785f4d6c4bf | 0.1930 ‚Üí rejected\n",
      "   ‚ûú 685bea046d23c23262115d2f | 0.1929 ‚Üí rejected\n",
      "   ‚ûú 68529a66bcf10b931eb7becd | 0.1925 ‚Üí rejected\n",
      "   ‚ûú 69393fa109d5458fbdf1781d | 0.1918 ‚Üí rejected\n",
      "   ‚ûú 68b927b697d1801b76070582 | 0.1896 ‚Üí rejected\n",
      "   ‚ûú 687630f6cab659d4c7569e1a | 0.1856 ‚Üí rejected\n",
      "   ‚ûú 68e76c8472a5ec1432f67f7b | 0.1855 ‚Üí rejected\n",
      "   ‚ûú 689591c4bb76c83d0d981ba9 | 0.1842 ‚Üí rejected\n",
      "   ‚ûú 68df6c4bcfa9d7bbe751fc93 | 0.1839 ‚Üí rejected\n",
      "   ‚ûú 684fc91abc64aa00fd7b2d93 | 0.1828 ‚Üí rejected\n",
      "   ‚ûú 68dccd31ad201e1ee6078a09 | 0.1802 ‚Üí rejected\n",
      "   ‚ûú 68dcb9c7be4f0a70c9781e4c | 0.1802 ‚Üí rejected\n",
      "   ‚ûú 68dcca5dad201e1ee6078801 | 0.1802 ‚Üí rejected\n",
      "   ‚ûú 685294edbcf10b931eb7be13 | 0.1785 ‚Üí rejected\n",
      "   ‚ûú 68ac0864d30790bfc2a72b49 | 0.1771 ‚Üí rejected\n",
      "   ‚ûú 686627138e27a08a983398c6 | 0.1764 ‚Üí rejected\n",
      "   ‚ûú 68a428bd9e5493e450cb493f | 0.1740 ‚Üí rejected\n",
      "   ‚ûú 68d4ffeeeca4b940ca06046e | 0.1734 ‚Üí rejected\n",
      "   ‚ûú 691595aefbe059035412fa15 | 0.1716 ‚Üí rejected\n",
      "   ‚ûú 6871f7aa4dbf0696b5ea0abb | 0.1710 ‚Üí rejected\n",
      "   ‚ûú 6899982a310d8d7ef36e837e | 0.1705 ‚Üí rejected\n",
      "   ‚ûú 6943be1a4393343324029407 | 0.1699 ‚Üí rejected\n",
      "   ‚ûú 685125833638325fc0d5e541 | 0.1685 ‚Üí rejected\n",
      "   ‚ûú 6891f0f2a3e4916f5a5fc33d | 0.1662 ‚Üí rejected\n",
      "   ‚ûú 68836cc123b3f4fdbd2ea727 | 0.1650 ‚Üí rejected\n",
      "   ‚ûú 684d4d957d783615f6da872e | 0.1642 ‚Üí rejected\n",
      "   ‚ûú 6883735c23b3f4fdbd2eaa60 | 0.1641 ‚Üí rejected\n",
      "   ‚ûú 68847facd376dbaf89969a24 | 0.1641 ‚Üí rejected\n",
      "   ‚ûú 6915932dfbe059035412f995 | 0.1614 ‚Üí rejected\n",
      "   ‚ûú 684d48967d783615f6da8514 | 0.1599 ‚Üí rejected\n",
      "   ‚ûú 684d4f027d783615f6da87c8 | 0.1594 ‚Üí rejected\n",
      "   ‚ûú 68d4fd5feca4b940ca060387 | 0.1592 ‚Üí rejected\n",
      "   ‚ûú 6914261970c72f8843d345ef | 0.1579 ‚Üí rejected\n",
      "   ‚ûú 68df6b6bcfa9d7bbe751fc5f | 0.1554 ‚Üí rejected\n",
      "   ‚ûú 69451caceb09b15bf667037e | 0.1523 ‚Üí rejected\n",
      "   ‚ûú 68a45023d0434b6f724c4c84 | 0.1522 ‚Üí rejected\n",
      "   ‚ûú 68512eab3638325fc0d5e717 | 0.1518 ‚Üí rejected\n",
      "   ‚ûú 69393eb609d5458fbdf177ec | 0.1495 ‚Üí rejected\n",
      "   ‚ûú 685127053638325fc0d5e578 | 0.1488 ‚Üí rejected\n",
      "   ‚ûú 6880bc63e8c8db3bed8e62fd | 0.1462 ‚Üí rejected\n",
      "   ‚ûú 685cf119c04002613f5549df | 0.1454 ‚Üí rejected\n",
      "   ‚ûú 6912f7faa174409501d682e5 | 0.1452 ‚Üí rejected\n",
      "   ‚ûú 6895ab1fbb76c83d0d981d2b | 0.1451 ‚Üí rejected\n",
      "   ‚ûú 684d4be47d783615f6da8613 | 0.1445 ‚Üí rejected\n",
      "   ‚ûú 68b298ccf48225e6addb9933 | 0.1431 ‚Üí rejected\n",
      "   ‚ûú 68b8194b9e1521b7a8147432 | 0.1415 ‚Üí rejected\n",
      "   ‚ûú 68627083defc6ec25cb661c1 | 0.1413 ‚Üí rejected\n",
      "   ‚ûú 689d87443bfdf7e0797a1e48 | 0.1397 ‚Üí rejected\n",
      "   ‚ûú 68a2d57d9d52520c6d8d6487 | 0.1384 ‚Üí rejected\n",
      "   ‚ûú 684d4e617d783615f6da878d | 0.1375 ‚Üí rejected\n",
      "   ‚ûú 68a2caa29d52520c6d8d62d1 | 0.1346 ‚Üí rejected\n",
      "   ‚ûú 68a96e8e0f7a9b9b9c5c8f4f | 0.1310 ‚Üí rejected\n",
      "   ‚ûú 6915902efbe059035412f926 | 0.1297 ‚Üí rejected\n",
      "   ‚ûú 687b3ecbc1bc4c80f2fe6ef3 | 0.1273 ‚Üí rejected\n",
      "   ‚ûú 684d560f8c77325205caf7b9 | 0.1273 ‚Üí rejected\n",
      "   ‚ûú 684d588d8c77325205caf868 | 0.1273 ‚Üí rejected\n",
      "   ‚ûú 684d57028c77325205caf7eb | 0.1273 ‚Üí rejected\n",
      "   ‚ûú 695e3b0e70e4c073e95a5c07 | 0.1240 ‚Üí rejected\n",
      "   ‚ûú 68b6896e0990b0064f8769d1 | 0.1217 ‚Üí rejected\n",
      "   ‚ûú 68c51237df8140229b23c5b5 | 0.1193 ‚Üí rejected\n",
      "   ‚ûú 684d4e5e7d783615f6da8783 | 0.1150 ‚Üí rejected\n",
      "   ‚ûú 68677c42c2c175d174d419e4 | 0.1128 ‚Üí rejected\n",
      "   ‚ûú 68a2cb199d52520c6d8d6308 | 0.1124 ‚Üí rejected\n",
      "   ‚ûú 686626478e27a08a9833988b | 0.1109 ‚Üí rejected\n",
      "   ‚ûú 68998178310d8d7ef36e816a | 0.1094 ‚Üí rejected\n",
      "   ‚ûú 6912eb5d0659cca26707f26b | 0.1094 ‚Üí rejected\n",
      "   ‚ûú 68a571d600ab81f477e48081 | 0.1083 ‚Üí rejected\n",
      "   ‚ûú 6915b5413676a98eb53c80b6 | 0.1057 ‚Üí rejected\n",
      "   ‚ûú 68e76bde72a5ec1432f67f43 | 0.1051 ‚Üí rejected\n",
      "   ‚ûú 68e76d1072a5ec1432f67fc2 | 0.1043 ‚Üí rejected\n",
      "   ‚ûú 689c48a877de8619092efa67 | 0.1031 ‚Üí rejected\n",
      "   ‚ûú 686620838e27a08a9833978a | 0.0994 ‚Üí rejected\n",
      "   ‚ûú 690c580de9c275feb8f4d82f | 0.0984 ‚Üí rejected\n",
      "   ‚ûú 685baf95de9f565472034547 | 0.0945 ‚Üí rejected\n",
      "   ‚ûú 68c3b3a5eedd9349d3c4f46b | 0.0920 ‚Üí rejected\n",
      "   ‚ûú 695b66152d516685d29d9cf7 | 0.0908 ‚Üí rejected\n",
      "   ‚ûú 6854fcfe1699190af3ef91c6 | 0.0904 ‚Üí rejected\n",
      "   ‚ûú 686cc40f6377313a8f23cb1a | 0.0873 ‚Üí rejected\n",
      "   ‚ûú 68662c108e27a08a983399b7 | 0.0846 ‚Üí rejected\n",
      "   ‚ûú 68c51347df8140229b23c61c | 0.0843 ‚Üí rejected\n",
      "   ‚ûú 68a2d8d99d52520c6d8d6512 | 0.0840 ‚Üí rejected\n",
      "   ‚ûú 69159792fbe059035412fa86 | 0.0819 ‚Üí rejected\n",
      "   ‚ûú 6883709923b3f4fdbd2ea8f7 | 0.0746 ‚Üí rejected\n",
      "   ‚ûú 690c5e49e9c275feb8f4d92f | 0.0745 ‚Üí rejected\n",
      "   ‚ûú 68a4390fd0434b6f724c497c | 0.0698 ‚Üí rejected\n",
      "   ‚ûú 686b67859bd8eee29ad4576d | 0.0673 ‚Üí rejected\n",
      "   ‚ûú 684d4ae27d783615f6da85a2 | 0.0668 ‚Üí rejected\n",
      "   ‚ûú 6888bda549f240bbef3048b7 | 0.0633 ‚Üí rejected\n",
      "   ‚ûú 685e7cd62f92b0462f6ab794 | 0.0579 ‚Üí rejected\n",
      "   ‚ûú 68a429dd9e5493e450cb49ad | 0.0573 ‚Üí rejected\n",
      "   ‚ûú 689c4b3177de8619092efad8 | 0.0533 ‚Üí rejected\n",
      "   ‚ûú 6883741823b3f4fdbd2eaacb | 0.0523 ‚Üí rejected\n",
      "   ‚ûú 6915b4f33676a98eb53c8074 | 0.0491 ‚Üí rejected\n",
      "   ‚ûú 68906865d2a0d2df520b6265 | 0.0432 ‚Üí rejected\n",
      "   ‚ûú 69182e8e2b8e1d66172e4199 | 0.0317 ‚Üí rejected\n",
      "   ‚ûú 689c4a2e77de8619092efaa0 | 0.0294 ‚Üí rejected\n",
      "   ‚ûú 68b5594b4e1eed80f349bfd2 | 0.0042 ‚Üí rejected\n",
      "   ‚ûú 688dc7599dd305268f00164c | -0.0126 ‚Üí rejected\n",
      "   ‚ûú 68d5014deca4b940ca0604a1 | -0.0137 ‚Üí rejected\n",
      "   ‚ûú 684d503a7d783615f6da881f | -0.0563 ‚Üí rejected\n",
      "   ‚ûú 68d4fec7eca4b940ca060413 | -0.0632 ‚Üí rejected\n",
      "   ‚ûú 68ca663a011f09de1b6a2421 | -0.0639 ‚Üí rejected\n",
      "\n",
      "üîé Processing Job: 68a9ba774905d4fcab4a5bc9\n",
      "üìä Found 0 resumes for this job\n",
      "\n",
      "üîé Processing Job: 690c43bf450fd808275d0f65\n",
      "üìä Found 0 resumes for this job\n",
      "‚úÖ Company JD Matching Done\n",
      "\n",
      "üè¢ Running JD Matching For Company: QBS Learning\n",
      "üîé Processing company: 69848e712bb40f1c432fd0bb\n",
      "\n",
      "üîé Processing Job: 698af5a9d0c34671dadbce62\n",
      "üìä Found 0 resumes for this job\n",
      "\n",
      "üîé Processing Job: 698af6d8d0c34671dadbceac\n",
      "üìä Found 0 resumes for this job\n",
      "‚úÖ Company JD Matching Done\n",
      "\n",
      "üè¢ Running JD Matching For Company: Cenveo Publishing\n",
      "üîé Processing company: 698d9b13152f2601d3481b5f\n",
      "‚ùå No OPEN status found for company Cenveo Publishing\n",
      "\n",
      "üéØ JD Matching Completed Successfully\n",
      "‚úÖ MongoDB closed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pymongo import MongoClient\n",
    "from bson import ObjectId\n",
    "from qdrant_client import QdrantClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# ================= LOAD ENV =================\n",
    "load_dotenv()\n",
    "\n",
    "MONGO_URI = os.getenv(\"MONGODB_URI\")\n",
    "DB_NAME = \"ats\"\n",
    "\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\")\n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
    "QDRANT_COLLECTION = \"resumes\"\n",
    "\n",
    "print(\"\\nüöÄ JD MATCHING AGENT STARTED (Best Score Relative Mode)\")\n",
    "\n",
    "# ================= MongoDB =================\n",
    "mongo = MongoClient(MONGO_URI)\n",
    "db = mongo[DB_NAME]\n",
    "companies = db[\"companies\"]\n",
    "applications = db[\"applications\"]\n",
    "jobs = db[\"jobs\"]\n",
    "job_statuses = db[\"job-statuses\"]\n",
    "\n",
    "print(\"‚úÖ MongoDB connected\")\n",
    "\n",
    "# ================= QDRANT =================\n",
    "qdrant = QdrantClient(\n",
    "    url=QDRANT_URL,\n",
    "    api_key=QDRANT_API_KEY,\n",
    "    prefer_grpc=False\n",
    ")\n",
    "print(\"‚úÖ Qdrant connected\")\n",
    "\n",
    "# ================= MODEL =================\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "print(\"‚úÖ Embedding model loaded\")\n",
    "\n",
    "# ================= CLEAN HTML =================\n",
    "def clean_html(raw_html):\n",
    "    soup = BeautifulSoup(raw_html, \"html.parser\")\n",
    "    text = soup.get_text(separator=\" \")\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "# ================= SEMANTIC JD MATCHING =================\n",
    "def jd_matching_agent(company):\n",
    "    company_id = company[\"_id\"]\n",
    "    print(f\"\\nüè¢ Running JD Matching For Company: {company.get('name')}\")\n",
    "    print(f\"üîé Processing company: {company_id}\")\n",
    "\n",
    "    # 1Ô∏è‚É£ Get OPEN status\n",
    "    open_status_doc = list(job_statuses.find({\n",
    "        \"company_id\": ObjectId(company_id),\n",
    "        \"jobStatus\": \"Open\"\n",
    "    }))\n",
    "\n",
    "    if not open_status_doc:\n",
    "        print(f\"‚ùå No OPEN status found for company {company.get('name')}\")\n",
    "        return\n",
    "\n",
    "    open_status_id = open_status_doc[0][\"_id\"]\n",
    "\n",
    "    # 2Ô∏è‚É£ Get OPEN jobs\n",
    "    open_jobs = list(jobs.find({\n",
    "        \"company_id\": ObjectId(company_id),\n",
    "        \"status\": str(open_status_id)\n",
    "    }))\n",
    "\n",
    "    if not open_jobs:\n",
    "        print(\"‚ùå No OPEN jobs found\")\n",
    "        return\n",
    "\n",
    "    # 3Ô∏è‚É£ Process each open job\n",
    "    for job in open_jobs:\n",
    "        job_id = str(job[\"_id\"])\n",
    "        job_description = job.get(\"description\", \"\")\n",
    "\n",
    "        if not job_description.strip():\n",
    "            print(f\"‚ö†Ô∏è Job {job_id} has no description\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nüîé Processing Job: {job_id}\")\n",
    "\n",
    "        cleaned_description = clean_html(job_description)\n",
    "        jd_vector = model.encode(cleaned_description).tolist()\n",
    "\n",
    "        try:\n",
    "            # Fetch all resumes and filter in Python\n",
    "            search_results = qdrant.query_points(\n",
    "                collection_name=QDRANT_COLLECTION,\n",
    "                query=jd_vector,\n",
    "                limit=100000,  # Fetch all\n",
    "                with_payload=True,\n",
    "                with_vectors=False\n",
    "            ).points\n",
    "\n",
    "            # Filter only resumes for this job\n",
    "            search_results = [\n",
    "                r for r in search_results\n",
    "                if r.payload.get(\"job_id\") == job_id\n",
    "            ]\n",
    "\n",
    "            print(f\"üìä Found {len(search_results)} resumes for this job\")\n",
    "\n",
    "            if not search_results:\n",
    "                continue\n",
    "\n",
    "            scores = [r.score for r in search_results if r.score is not None]\n",
    "\n",
    "            if not scores:\n",
    "                print(\"‚ùå No similarity scores found\")\n",
    "                continue\n",
    "\n",
    "            # üéØ Best-score based cutoff\n",
    "            best_score = max(scores)\n",
    "            cutoff = best_score * 0.63\n",
    "\n",
    "            print(f\"üèÜ Best Score: {best_score:.4f}\")\n",
    "            print(f\"üéØ Selection Cutoff (63% of Best): {cutoff:.4f}\")\n",
    "\n",
    "            # 4Ô∏è‚É£ Update application status\n",
    "            for result in search_results:\n",
    "                payload = result.payload or {}\n",
    "                application_id = payload.get(\"application_id\")\n",
    "                score = result.score\n",
    "\n",
    "                if not application_id or score is None:\n",
    "                    continue\n",
    "\n",
    "                status = \"selected\" if score >= cutoff else \"rejected\"\n",
    "\n",
    "                applications.update_one(\n",
    "                    {\"_id\": ObjectId(application_id)},\n",
    "                    {\"$set\": {\"resume_status\": status}}\n",
    "                )\n",
    "\n",
    "                print(f\"   ‚ûú {application_id} | {score:.4f} ‚Üí {status}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Qdrant query failed: {e}\")\n",
    "\n",
    "    print(\"‚úÖ Company JD Matching Done\")\n",
    "\n",
    "# ================= RUN =================\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        ai_companies = list(companies.find({\"aiFeaturesEnabled\": True}))\n",
    "\n",
    "        if not ai_companies:\n",
    "            print(\"‚ùå No AI enabled companies found\")\n",
    "        else:\n",
    "            print(f\"üè¢ Found {len(ai_companies)} AI enabled companies\")\n",
    "\n",
    "            for company in ai_companies:\n",
    "                jd_matching_agent(company)\n",
    "\n",
    "        print(\"\\nüéØ JD Matching Completed Successfully\")\n",
    "    finally:\n",
    "        mongo.close()\n",
    "        print(\"‚úÖ MongoDB closed\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
